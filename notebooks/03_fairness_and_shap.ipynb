{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf675500",
   "metadata": {},
   "source": [
    "# 03_fairness_and_xai.ipynb\n",
    "## Fairness Evaluation & Explainable AI\n",
    "We evaluate the trained model for gender bias and use SHAP and LIME for explainability.\n",
    "\n",
    "## Fairness Metrics\n",
    "Calculating accuracy and selection rate by gender.\n",
    "\n",
    "## SHAP Explainability\n",
    "Visualizing which words influence model predictions.\n",
    "\n",
    "## LIME Explainability\n",
    "Explaining a single prediction with LIME.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0463e99a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 03_fairness_and_xai.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import shap\n",
    "from fairlearn.metrics import MetricFrame, selection_rate, demographic_parity_difference\n",
    "import matplotlib.pyplot as plt\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "# Load processed data\n",
    "df = pd.read_csv(\"data/processed/processed_data.csv\")\n",
    "X_text = df[\"cleaned_resume\"]\n",
    "y = df[\"label\"]\n",
    "sensitive = df[\"gender\"]\n",
    "\n",
    "# Load model & vectorizer\n",
    "model = joblib.load(\"artifacts/logreg_model.pkl\")\n",
    "tfidf = joblib.load(\"artifacts/tfidf_vectorizer.pkl\")\n",
    "X_vect = tfidf.transform(X_text)\n",
    "\n",
    "# Fairness metrics\n",
    "y_pred = model.predict(X_vect)\n",
    "metrics = {\"accuracy\": accuracy_score, \"selection_rate\": selection_rate}\n",
    "mf = MetricFrame(metrics=metrics, y_true=y, y_pred=y_pred, sensitive_features=sensitive)\n",
    "print(\"Group-wise metrics:\")\n",
    "print(mf.by_group)\n",
    "\n",
    "dp_diff = demographic_parity_difference(y, y_pred, sensitive_features=sensitive)\n",
    "print(\"\\nDemographic Parity Difference:\", dp_diff)\n",
    "\n",
    "# SHAP\n",
    "explainer = shap.LinearExplainer(model, X_vect)\n",
    "shap_values = explainer.shap_values(X_vect)\n",
    "shap.summary_plot(shap_values, X_vect, feature_names=tfidf.get_feature_names_out(), show=True)\n",
    "\n",
    "# LIME example\n",
    "explainer_lime = LimeTextExplainer(class_names=[\"Rejected\",\"Selected\"])\n",
    "exp = explainer_lime.explain_instance(X_text.iloc[0],\n",
    "                                      lambda x: model.predict_proba(tfidf.transform(x)),\n",
    "                                      num_features=10)\n",
    "exp.show_in_notebook()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
